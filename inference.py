#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, time, json, logging
from pathlib import Path
import numpy as np
from PIL import Image

from pycoral.utils import edgetpu
from pycoral.adapters import common, classify

# â”€â”€â”€ 0. Logger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s][%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
log = logging.getLogger(__name__)

# â”€â”€â”€ 1. Edge-TPU í™•ì¸ ë° ì¸í„°í”„ë¦¬í„° ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
devices = edgetpu.list_edge_tpus()
using_tpu = bool(devices)

MODEL_PATH = Path('models/model_quant_edgetpu.tflite')
if using_tpu:
    log.info(f"âœ… Edge TPU detected: {devices}")
    interpreter = edgetpu.make_interpreter(str(MODEL_PATH), device="usb")
else:
    log.warning("âš ï¸ Edge TPU not found â€“ CPU fallback")
    from tflite_runtime.interpreter import Interpreter
    interpreter = Interpreter(model_path=str(MODEL_PATH))

interpreter.allocate_tensors()
input_w, input_h = common.input_size(interpreter)
log.info(f"Model input size: {input_w}Ã—{input_h} RGB")

# â”€â”€â”€ 2. í´ë˜ìŠ¤ ë¼ë²¨ ë¡œë“œ (labels.txt ì‚¬ìš© ë˜ëŠ” ì§ì ‘ ì§€ì •) â”€â”€â”€
LABELS_PATH = Path('models/labels.txt')
if LABELS_PATH.exists():
    labels = LABELS_PATH.read_text().splitlines()
else:
    labels = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4']
log.info(f"Labels: {json.dumps(labels, ensure_ascii=False)}")

# â”€â”€â”€ 3. ë³´ì¡° í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess(img_path: Path) -> np.ndarray:
    """PIL â†’ Numpy (uint8) + ë¦¬ì‚¬ì´ì¦ˆ"""
    img = Image.open(img_path).convert('RGB')
    img = img.resize((input_w, input_h), Image.BILINEAR)
    return np.asarray(img).astype(np.uint8)

def infer(img_np: np.ndarray):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡  â†’ (pred_id, score)"""
    common.set_input(interpreter, img_np)
    t0 = time.perf_counter()
    interpreter.invoke()
    latency = (time.perf_counter() - t0) * 1000  # ms
    preds = classify.get_classes(interpreter, top_k=1)
    pred_id, score = preds[0].id, preds[0].score
    return pred_id, score, latency

# â”€â”€â”€ 4. ìº¡ì²˜ & ì¶”ë¡  ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CAPTURE_DIR = Path('./captured_images')
CAPTURE_DIR.mkdir(exist_ok=True, parents=True)
CAPTURE_CMD = "libcamera-still -n -o {dst} --width 1640 --height 1232"
INTERVAL = 30  # seconds

log.info("=== Start realtime inference loop ===")
while True:
    ts = time.strftime("%Y%m%d_%H%M%S")
    img_file = CAPTURE_DIR / f"capture_{ts}.jpg"
    cmd = CAPTURE_CMD.format(dst=img_file)
    log.info(f"ğŸ“· Capturingâ€¦ ({cmd})")
    os.system(cmd)

    if not img_file.exists():
        log.warning(f"Capture failed: {img_file} not found")
        time.sleep(INTERVAL)
        continue

    img_np = preprocess(img_file)
    pred_id, score, latency = infer(img_np)
    pred_label = labels[pred_id] if pred_id < len(labels) else f"id_{pred_id}"

    log.info(f"{img_file.name} â†’ {pred_label} (score={score:.3f}, {latency:.1f} ms)")

    # ì €ì¥ ê³µê°„ ì ˆì•½: ì¶”ë¡  í›„ ì´ë¯¸ì§€ ì‚­ì œí•˜ë ¤ë©´ ì£¼ì„ í•´ì œ
    img_file.unlink(missing_ok=True)

    log.info(f"Waiting {INTERVAL}s...\n")
    time.sleep(INTERVAL)
