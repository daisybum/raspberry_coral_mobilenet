#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Edge TPU MobileNetV3-Large ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
* testset/
   â”œâ”€ hazy/
   â”‚   â”œâ”€ img001.jpg â€¦
   â”œâ”€ normal/
   â””â”€ â€¦
"""

import os, time, json, itertools
import numpy as np
from PIL import Image
from pathlib import Path
from collections import defaultdict, Counter

from pycoral.utils import edgetpu
from pycoral.adapters import common, classify  # â¬…ï¸ pycoral API

# â”€â”€â”€ 0. ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IMAGE_DIR   = Path('/workspace/testset')      # í´ëž˜ìŠ¤ë³„ í•˜ìœ„ í´ë”
MODEL_PATH  = Path('models/mobilenet_int8.tflite')
TOP_K       = 1                               # Top-k ê²°ê³¼ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©

# â”€â”€â”€ 1. Edge TPU ì¸í„°í”„ë¦¬í„° ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
interpreter = edgetpu.make_interpreter(str(MODEL_PATH))
interpreter.allocate_tensors()

input_width, input_height = common.input_size(interpreter)
print(f"âš™ï¸  Model expects {input_width}Ã—{input_height} RGB")

# â”€â”€â”€ 2. í´ëž˜ìŠ¤ ë¼ë²¨ ì¶”ì¶œ(í´ë”ëª… ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class_to_index = {cls: idx for idx, cls in
                  enumerate(sorted([d.name for d in IMAGE_DIR.iterdir() if d.is_dir()]))}
index_to_class = {v: k for k, v in class_to_index.items()}
print(json.dumps(index_to_class, indent=2, ensure_ascii=False))

# â”€â”€â”€ 3. ë³´ì¡° í•¨ìˆ˜: ì „ì²˜ë¦¬ & ì¶”ë¡  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess(img_path):
    """PIL.Image â†’ ëª¨ë¸ ìž…ë ¥ í…ì„œ(float32 ë˜ëŠ” uint8)"""
    img = Image.open(img_path).convert('RGB').resize(
        (input_width, input_height), Image.BILINEAR)
    arr = np.asarray(img).astype(np.uint8)         # ëª¨ë¸ì´ uint8 ìž…Â·ì¶œë ¥
    return arr

def infer(image_np):
    """Numpy(HxWx3 uint8) â†’ Top-k í´ëž˜ìŠ¤ ì¸ë±ìŠ¤"""
    common.set_input(interpreter, image_np)
    interpreter.invoke()
    classes = classify.get_classes(interpreter, top_k=TOP_K)  # score í¬í•¨ ê°ì²´ ë¦¬ìŠ¤íŠ¸
    return [(c.id, c.score) for c in classes]

# â”€â”€â”€ 4. ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
results = defaultdict(list)   # {true_cls: [(pred_cls, score), â€¦]}
latencies = []

for cls_dir in IMAGE_DIR.iterdir():
    if not cls_dir.is_dir():          # íŒŒì¼ ìŠ¤í‚µ
        continue
    true_idx = class_to_index[cls_dir.name]
    for img_path in cls_dir.glob('*'):
        img_np = preprocess(img_path)
        t0 = time.perf_counter()
        preds = infer(img_np)
        latencies.append(time.perf_counter() - t0)

        pred_idx, score = preds[0]
        results[true_idx].append((pred_idx, score))

# â”€â”€â”€ 5. ì§€í‘œ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
total, correct = 0, 0
confusion = Counter()  # (true, pred) ìŒ ì¹´ìš´íŠ¸

for true_idx, lst in results.items():
    for pred_idx, _ in lst:
        confusion[(true_idx, pred_idx)] += 1
        total += 1
        if pred_idx == true_idx:
            correct += 1

acc = correct / total if total else 0
avg_latency = np.mean(latencies) * 1000  # ms

# â”€â”€â”€ 6. ë¦¬í¬íŠ¸ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print(f"\nðŸ“Š ì „ì²´ ì´ë¯¸ì§€: {total}")
print(f"âœ… Top-1 ì •í™•ë„ : {acc:.4%}")
print(f"â±  í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_latency:.2f} ms (Edge TPU)")

print("\nðŸ” í˜¼ë™ í–‰ë ¬(ìƒ˜í”Œ ìˆ˜ â‰¥1ì¸ í•­ëª©ë§Œ):")
for (t, p), n in sorted(confusion.items()):
    if n > 0:
        print(f"  {index_to_class[t]:<20} â†’ {index_to_class[p]:<20}: {n}")
